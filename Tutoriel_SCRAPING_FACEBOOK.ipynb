{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIEL  SCRAPING FACEBOOK \n",
    "###  Cas: décès du président Jacques Chirac en septembre 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Prénoms       |     Nom         |     Email          |                                     |     Lieu    |   Date   |\n",
    "| ------------- |: -------------: |--------------------|                                     | ------------|----------|\n",
    "| Amadou lamarana      | DIALLO               | mailsdiallo@gmail.com|                       | Paris       | 16-06-2021|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LES ÉTAPES :\n",
    "\n",
    "#### A ) Importer les modules nécessaires\n",
    "\n",
    "#### B ) Configuration  et lancement du navigateur webdriver\n",
    "\n",
    "#### C ) La connexion sur le compte facebook pour récupérer les données ou posts\n",
    "\n",
    "#### D) Parcours de toute la page avec un système de scrolling afin de récuperer tous les posts pertinents par rapport à notre thématique \"le décès du président Jacques Chirac\" et les résultats sont affichés sur la page\n",
    "\n",
    "#### E) Récupération des articles des tous les posts sur la page de résultat \n",
    "\n",
    "#### F) Récupérer les liens des posts\n",
    "\n",
    "#### G) Création d'un DataFrame df pour la persistance des liens\n",
    "\n",
    "#### H) Sauvegarder les liens dans un fichier au format csv\n",
    "\n",
    "#### I) Utilisation du package facebook-scraper\n",
    "\n",
    "#### J) MongoDB pour la sauvegarde des données en local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A ) Importer les modules nécessaires\n",
    "\n",
    "    * Selenuim :https://selenium-python.readthedocs.io/index.html\n",
    "\n",
    "    * time et math uuid sont natifs à python lors de son l'installation\n",
    "\n",
    "    * pandas: https://pandas.pydata.org/\n",
    "\n",
    "    * cleantext : https://pypi.org/project/clean-text/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import time\n",
    "import math\n",
    "import uuid\n",
    "##import pandas \n",
    "import pandas as pd\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B ) Configuration  et lancement du navigateur webdriver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identifiant de connexion et mot de passe .. à personnaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifiant =\"your_username\"\n",
    "mot_de_passe =\"your_password\"\n",
    "credentials= (identifiant, mot_de_passe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Nous avons la configuration du webdriver en local avec \n",
    "les options élémentaires.\n",
    "\"\"\"\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "chrome_options.add_argument('--incognito')\n",
    "chrome_options.add_experimental_option(\"prefs\",prefs)\n",
    "\"\"\"\n",
    "lien du webdriver :chrome\n",
    "\"\"\"\n",
    "exec_path = \"../chromedriver\"\n",
    "\"\"\"\n",
    "Exécution du webdriver\n",
    "\"\"\"\n",
    "browser = webdriver.Chrome(executable_path=exec_path, options=chrome_options)\n",
    "\"\"\"\n",
    "Accéder au site facebook\n",
    "\"\"\"\n",
    "browser.get(\"https://www.facebook.com\")\n",
    "\n",
    "\"\"\"\n",
    "Acceptation des cookies pour continuer la simulation de connexion\n",
    "\"\"\"\n",
    "WebDriverWait(browser, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[title='Tout accepter']\"))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C ) La connexion sur le compte facebook pour récupérer les données ou posts\n",
    "La fonction login() aide à se connecter en utilisant des paramètres de connexion valides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login():\n",
    "    \"\"\"\n",
    "    Nous definissons d'une fonction login afin de se connecter sur facebook \n",
    "    avec les credentials ci dessous.\n",
    "    Les taches nécessaires sont majoirtairement automatiques. \n",
    "    Le système reconnait les champs requis et fait lui même le remplissage. \n",
    "    \"\"\"\n",
    "    #target username\n",
    "    \"\"\"\n",
    "    Detecter puis Renseigner l'identifiant (email et mot de passe)\n",
    "    \"\"\"\n",
    "    email = WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='email']\")))\n",
    "    password = WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='pass']\")))\n",
    "    \"\"\"\n",
    "    Toujours vider les champs inputs grace au méthode clear() avant le remplissage\n",
    "    \"\"\"\n",
    "    email.clear()\n",
    "    #email = driver.find_element_by_id(\"email\")\n",
    "    identifiant =credentials[0]\n",
    "    mot_de_passe =credentials[1]\n",
    "    \"\"\"\n",
    "    Renseigner le username\n",
    "    \"\"\"\n",
    "    email.send_keys(identifiant)\n",
    "    #Password = driver.find_element_by_id(\"pass\")\n",
    "    password.clear()\n",
    "    \"\"\"\n",
    "    Renseigner le mot de passe\n",
    "    \"\"\"\n",
    "    password.send_keys(mot_de_passe)\n",
    "    button = WebDriverWait(browser, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "    \"\"\"\n",
    "    connexion effectuée.. puis libérer \n",
    "    \"\"\"\n",
    "    pass \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La connexion proprement dite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Puis action de se connecter sur Facebook \n",
    "\"\"\"\n",
    "login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Parcours de toute la page avec un système de scrolling afin de récuperer tous les posts pertinents par rapport à notre thématique \"le décès du président Jacques Chirac\" et les résultats sont affichés sur la page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Les données sont filtrées d'avance sur Facebook et classé par Année, Publication publiques, etc. \n",
    "Nous allons définir le lien essentiel pour le résultat directement, \n",
    "\"\"\"\n",
    "url_complet='https://www.facebook.com/search/posts?q=le%20d%C3%A9c%C3%A9s%20du%20pr%C3%A9sident%20%20jacques%20chirac&filters=eyJycF9hdXRob3I6MCI6IntcIm5hbWVcIjpcIm1lcmdlZF9wdWJsaWNfcG9zdHNcIixcImFyZ3NcIjpcIlwifSIsInJwX2NyZWF0aW9uX3RpbWU6MCI6IntcIm5hbWVcIjpcImNyZWF0aW9uX3RpbWVcIixcImFyZ3NcIjpcIntcXFwic3RhcnRfeWVhclxcXCI6XFxcIjIwMTlcXFwiLFxcXCJzdGFydF9tb250aFxcXCI6XFxcIjIwMTktMVxcXCIsXFxcImVuZF95ZWFyXFxcIjpcXFwiMjAxOVxcXCIsXFxcImVuZF9tb250aFxcXCI6XFxcIjIwMTktMTJcXFwiLFxcXCJzdGFydF9kYXlcXFwiOlxcXCIyMDE5LTEtMVxcXCIsXFxcImVuZF9kYXlcXFwiOlxcXCIyMDE5LTEyLTMxXFxcIn1cIn0ifQ%3D%3D'\n",
    "\n",
    "\"\"\"\n",
    "Nous tentons d'accéder au lien \"url_complet\"\n",
    "\"\"\"\n",
    "browser.get(url_complet)\n",
    "\n",
    "\"\"\"methode scrolling pour récuperer plus de données dans la page\"\"\"\n",
    "\n",
    "last_height = browser.execute_script(\"return document.body.scrollHeight\") \n",
    "\"\"\"\n",
    "Parcours autant que nécessaire jusqu'a atteindre le fond de la page\n",
    "\"\"\"\n",
    "while True:\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \"\"\"\n",
    "    Attendre 2 secondes '2 s' avant chaque scroll vers le bas\n",
    "    \"\"\"\n",
    "    time.sleep(2)\n",
    "    \"\"\"\n",
    "    Recuperer la taille courante du frame\n",
    "    \"\"\"\n",
    "    new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    \"\"\"\n",
    "    Si la taille courante est égale à la taille maximale alors sortir \n",
    "    de boucle grâce une instrcution break\n",
    "    \"\"\"\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E) Récupération des articles des tous les posts sur la page de résultat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "recuepérer les webElement(qui contient les liens informations du post) des posts de la page affichée\n",
    "\"\"\"\n",
    "#recherche =browser.find_elements_by_xpath('//*[@id=\"mount_0_0_wk\"]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div[2]')\n",
    "recherche = browser.find_elements(By.TAG_NAME, 'div[role=\"article\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "recherche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F) Récupérer les liens des posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Nous allons récupérer les liens des posts pertinents chargés dans une liste\n",
    "\"\"\"\n",
    "data = [] ## liste des liens\n",
    "\"\"\"\n",
    "Boucle sur les posts pertinents déja existants\n",
    "\"\"\"\n",
    "for r in recherche:\n",
    "    \"\"\"\n",
    "    les balises \"a\" contenant les liens des posts. ce que nous cherchons: 'anchors'\n",
    "    \"\"\"\n",
    "    \n",
    "    anchors = r.find_elements_by_tag_name('a[role=\"link\"]')[-1]\n",
    "    \"recuperer la valeur de href: lien du post\"\n",
    "    link = anchors.get_attribute('href')\n",
    "    \n",
    "    \"\"\"\n",
    "    Ne récuperer que les liens posts\n",
    "    \"\"\"\n",
    "    if \"posts\" in link:\n",
    "        data.append(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G) Création d'un DataFrame df pour la persistance des liens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stocker les données dans un dataframe afin d'une prochaine utilisation\n",
    "\"\"\"\n",
    "df = pd.DataFrame(data, columns=['Link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppresion des duplicats\n",
    "\"\"\"\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H) Sauvegarder les liens dans un fichier au format csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Liens_Post_Facebook.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I) Utilisation du package facebook-scraper\n",
    "\n",
    "Lien web: https://pypi.org/project/facebook-scraper/\n",
    "\n",
    "\n",
    "Installation :  pip install facebook-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facebook_scraper import get_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Renseigner le login et le mot du compte qui sera utilisé pour se connecter sur Facebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Module de gestion de fichier et du telechargement des images en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J) Recupération des données sur Facebook  à partir des données\n",
    "###### Les données à utiliser:  \n",
    "    *** notre liste d'url disponible sur avec la variable data OU  \n",
    "    *** récuperer les liens au niveau du dataframe  OU  \n",
    "    *** par le fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "#df= pd.read_csv('Liens_Post_Facebook.csv')\n",
    "#data = list(df['Link'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utilisation du package facebook-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dictionnaire posts pour enregistrer les données..\n",
    "\"\"\"\n",
    "posts ={'texts':[],'image_link':[],'image_local_path':[], 'comments':[]}\n",
    "\"\"\"\n",
    "boucle sur les liens de données recupérées\n",
    "\"\"\"\n",
    "for post in get_posts(post_urls=data, credentials=credentials,options={\"comments\": True}):\n",
    "    \"\"\"\n",
    "        text_NA: donnée à enregistrer en cas d'absence de texte\n",
    "    \"\"\"\n",
    "    text_NA ='XXX'\n",
    "    \"\"\"\n",
    "        si le texte du post est défini\n",
    "    \"\"\"\n",
    "    if post['text'] is not None:\n",
    "        \"\"\"\n",
    "            nettoyage du texte et ajout sur la liste du dictionnaire posts['texts']\n",
    "        \"\"\"\n",
    "        posts['texts'].append(clean(post['text'].strip(),normalize_whitespace=True, no_line_breaks=True, lang='fr'))\n",
    "    else:\n",
    "        \"\"\"\n",
    "            si pas de text\n",
    "        \"\"\"\n",
    "        posts['texts'].append(text_NA)\n",
    "    \"\"\"\n",
    "        Si l'image est définie alors traiement et gestion de l'image\n",
    "    \"\"\"\n",
    "    if post['image'] is not None:\n",
    "        \n",
    "        posts['image_link'].append(post['image'])\n",
    "        \"\"\"\n",
    "            Télécharger l'image si elle est disponible\n",
    "            # 1 : dossier de travail\n",
    "            # 2 : mention du dossier de sauvegarde des images en local (dossier images_facebook)\n",
    "            # 3 : si le dossier n'existe pas, alors le créer\n",
    "            # 4 : filename du fichier avec l'id du post_id du post sur facebook combiné à un uuid() pour eviter les duplications\n",
    "        \"\"\"\n",
    "        path = os.getcwd() # 1\n",
    "        path = os.path.join(path, 'images_facebook') # 2\n",
    "        if  os.path.exists(path)== False: # 3\n",
    "            os.mkdir(path) # 3\n",
    "        rename_file = os.path.join(path, str(post['post_id'])+str(uuid.uuid1())+'.png') # 4\n",
    "        \"\"\"\n",
    "            Si le fichier n'existe pas en répertoire \n",
    "        \"\"\"\n",
    "        if os.path.exists(rename_file) == False:\n",
    "            try:\n",
    "                \"\"\"\n",
    "                    tentative de telechargement de l'image et sauvgarde sur un répertoire crée à l'occasion\n",
    "                \"\"\"\n",
    "                wget.download(post['image'], rename_file)\n",
    "                \n",
    "                posts['image_local_path'].append(rename_file)\n",
    "                \n",
    "            except:\n",
    "                \"\"\"Cas où le téléchargement a échoué, j'ai jugé nécessaire de mettre en placeholder, \n",
    "                une image 'no_image' pour sympbiliser l'absence de l'élément\n",
    "                \"\"\"\n",
    "                posts['image_local_path'].append(path+'/images_facebook/no_image.png')\n",
    "                \n",
    "    else:\n",
    "        \"\"\"\n",
    "             Si il n'y a pas d'image.alors renseigner XXX sur le lien de notre dictioonaire. et pour lien d'image en local, l'image par défaut\n",
    "        \"\"\"\n",
    "        posts['image_link'].append('XXX')\n",
    "        posts['image_local_path'].append(path+'/images_facebook/no_image.png')\n",
    "        \n",
    "    \"\"\"\n",
    "        Si les commentaires existent alors: \n",
    "            1) Opération de nettoyage du texte\n",
    "            2) Mettre tous les commentaires du post dans une même liste pour faciliter le traitement futur\n",
    "    \"\"\"\n",
    "    if post['comments_full'] is not None:\n",
    "        comment_sanitized =[]\n",
    "        \"\"\"\n",
    "            Parcourir les commentaires du post\n",
    "        \"\"\"\n",
    "        for comment in post['comments_full']:\n",
    "            \"\"\"\n",
    "            Nettoyage du texte des commentaires et sauvegader dans une liste \"comment_sanitized\"\n",
    "            \"\"\"\n",
    "            comment_sanitized.append(clean(comment['comment_text'],normalize_whitespace=True, no_line_breaks=True, lang='fr'))\n",
    "        \n",
    "        \"\"\"\n",
    "            Une fois la boucle terminée, la liste des commentaires nettoyés est ajouté dans notre dictionnaire 'posts' au niveau de la liste \"comments\"\n",
    "        \"\"\"\n",
    "        posts['comments'].append(comment_sanitized)\n",
    "        \"\"\"\n",
    "            Vider la liste des commentaires nettoyés du post et passage pour le prochain post\n",
    "        \"\"\"\n",
    "        comment_sanitized =[]\n",
    "    else:\n",
    "        \"\"\"\n",
    "            Si il n'y a pas de commentaire pour le post alors .. la valeur 'XXX' lui est attribuée\n",
    "        \"\"\"\n",
    "        posts['comments'].append('XXX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Réorganisation des commentaires sous format liste de dictionnaires\n",
    "<code>    post :{\n",
    "                'text': le_texte,\n",
    "                'image': l_image_local,\n",
    "                'comments': [{comment1},{comment_2},......]\n",
    "            } </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Nous allons organiser les commentaires pour chaque post, sous le format ci-dessus. \n",
    "pour facilter la representaion et le stockage en mongoDB\n",
    "\"\"\"\n",
    "comments = {}\n",
    "all_comments =[]\n",
    "for k in range(len(posts['comments'])):\n",
    "    for com in posts['comments'][k]:\n",
    "        comment = {'comment_text': com }\n",
    "        all_comments.append(comment)\n",
    "    comments[k] = all_comments\n",
    "    all_comments = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J) MongoDB pour la sauvegarde des données en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Nous allons utiliser le package pymongo pour interagir avec MongoDB installé en local.\n",
    "Les paramètres sont ceux définis par défaut .. sans user sans mot de passe\n",
    "pprint sert à un afficahge pour une facilité de lecture et de visualisation.\n",
    "\"\"\"\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "\"\"\"\n",
    "Etape1: Se connecter à la base MongoDB\n",
    "\"\"\"\n",
    "client = MongoClient(port=27017)\n",
    "\"\"\"\n",
    "Création de la base de données 'db_name'\n",
    "\"\"\"\n",
    "db=client.db_name\n",
    "\n",
    "\"\"\"\n",
    "Etape 2: Schema de données\n",
    "\"\"\"\n",
    "n = len(posts['texts']) ## nombre de posts \n",
    "\"\"\"\n",
    "parcours de 0 à n-1\n",
    "le but de cet ensemble d'istruction est de définir un dictionnaire simple pour chaque post pour des rasions\n",
    " **** facilité l'affichage et les insertions dans la base de données mongodb\n",
    "\"\"\"\n",
    "for i in range(n):\n",
    "    post ={\n",
    "        'text' : posts[\"texts\"][i],\n",
    "        'image':posts['image_local_path'][i],\n",
    "        'comments':comments[i]\n",
    "    }\n",
    "    #print(comments[i])\n",
    "    \"\"\"\n",
    "    Etape 3: Insertion de chaque post directement dans la base de données db.db_name \n",
    "    db_name est le nom de la base de données\n",
    "    \"\"\"\n",
    "    result=db.db_name.insert_one(post)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste de bases de données en local sur mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Petite manipulation pour la visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Affichage des documents: db_name est le nom de la base de données\n",
    "\"\"\"\n",
    "for d in db.db_name.find():\n",
    "    pprint(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nombre de documents dans la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesdonnes = db.db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "mesdonnes.count_documents({})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='text text-primary'> Nos documents sont bien enregistrés dans la base mongoDB </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons implémenté des scripts à l'aide Selenuim, et le package facebook-scraper pour la recherche de l'information à savoir les posts, les images et les commentaires associés sur Facebook sur la thématique  'le décès du président Jacques Chirac' en septembre 2019.\n",
    "Nous avons ensuite pû implémenter le script pour l'enregistrement dans une base de données MongoDB. \n",
    "Nous avons pas utilisé une application Facebook pour se servir des GraphAPI de Facebook, vu que la thématique demandé n'est pas lié à une page quelconque. Ce qui nous a amené à implementer un script de scrapping à l'aide Sélénuim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
